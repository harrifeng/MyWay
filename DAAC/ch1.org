* chapter 1: 引论
** 本书讨论的内容
   + 作者首先举例了Kth element和字谜游戏的问题，算法的优势就是能降低复杂度，从而
     在面对数据量的时候，比较从容。这也就是这本书要讨论的内容
** 数学知识复习
*** 指数:
    + 2^N + 2^N = 2^(N+1)
*** 对数
    + 在计算机科学中，所有对数都是以2为底的
    + logAB = logA + logB
*** 级数
    + sumof(A^i | 0<=i<=N) = (A^(N+1) - 1)/A-1
    + 推演方法
      #+begin_src c
        S = 1 + A^1 + A^2 + A^3 ...
        AS =    A^1 + A^2 + A^3 + A^4...
        S - AS = 1
        S = 1/(1 - A)
      #+end_src
    + 我们经常使用A=2时候的情况:sumof(2^i | 0<=i<=N) = 2^(N+1) - 1
*** 模运算
    + 如果N整除A-B,那么就说A与B模N同余
** 递归的简单介绍
   + 当一个函数用自身来定义时，就称为递归的。
   + 递归的特点就是需要某些基准情况，它们不用递归就能算出来。
     #+begin_src c++
       int f(int x)
       {
           /* Base Case */
           if (x == 0)
               return 0;
           else
               return 2 * f(x - 1) + x * x;
       }
     #+end_src
   + 打印输出整数是一个很好的递归的例子，这个例子还有个局部的优化方法:使用
     n-(n/10)*10 来代替n%10, 因为mod这个过程消耗很大
     #+begin_src c++
       #include <iostream>
       using namespace std;
       
       void printOut(int n)
       {
           if (n >= 10)
               printOut(n / 10);
           /*
            *use n - (n / 10) * 10 is more effective than mod, as 
            *mod is very costly for CPU
            *cout << n - (n / 10) * 10;
            */
           cout << n % 10;
       }
       
       int main(int argc, const char *argv[])
       {
           printOut(123459);    
           cout << endl;
           return 0;
       }
     #+end_src
   + 递归要确保所有递归调用都能运行，在逻辑上不能又错误
   + 最后，递归最好能满足合成效益法则:在求解一个问题的同一实例时，切勿在不同的递
     归调用中做重复的工作。比如，使用递归来计算斐波那契数之类的简单函数值不是一
     个特别好的注意，就是因为递归中有很多重复的操作。

* chapter 2: 算法分析
** 数学基础
   + 主要就是说了大O复杂度分析法
** 模型
** 要分析的问题
** 运行时间计算
*** 运行时间中的对数
    + 二分查找法:二分查找法因为每次都会去掉一半的搜索项目，所以最后的复杂度是O(lgN)
    + 欧几里得算法:是求两个整数的最大公约数的算法，也就是我们常说的辗转相除算法
    + 幂运算:求幂的话，最明显的是使用N-1次的乘法自乘，但是还有更高效的运算方法，
      那就是利用递归:
      #+begin_src c++
        long pow(long x, int n)
        {
            if (n == 0)
                return 1;
            if (n == 1)
                return x;
            if (isEven(n))
                return pow(x * x, n / 2);
            else
                return pow(x * x, n / 2) * x;
        }
      #+end_src
* chapter 3: 表，栈和队列
** 抽象数据类型:
   + ADT就是对一种数据结构一系列的增删改查操作
** 表ADT:
*** 表的简答数组实现
    + 如果对表的操作通常是在末尾插入元素，之后只有数组访问，在这种情况下，数组是
      实现表比较好的方式
    + 表的弱点就是插入和删除代价昂贵
*** 简单链表
    + 克服数组形式表插入删除代价昂贵的缺点，产生了链表
*** STL的向量和表
    + 在STL中，数组实现表的代表就是vector，链表实现表的代表就是list，其中在list
      是双向链表。
    + vector和list都支持的函数如下:
      - int size() const
      - void clear()
      - bool empty()
      - void push_back(const Object& x)
      - void pop_back() 
      - const Object &back() const
      - const Object &front() const
    + vector在头部插入效率不高，所以下面两个函数只被list支持
      - void push_front(const Object &x)
      - void pop_front()
    + vector的特点是数据内存在一块，所以有以下特殊函数
      - Object& operator[]
      - Object& at(int idx)
      - int capacity() const
      - void reserve(int new Capacity)
*** 迭代器
    + 获得迭代器的方法:
      - iterator begin()
      - iterator end()
    + 迭代器方法
      - itr++ & ++itr
      - *itr
      - itr1 == itr2 如果两者指向同一个位置才为true
    + 需要迭代器的容器操作
      - iterator insert(iterator pos, Object &x)
      - iterarot erase(iterator pos)
      - iterator erase(iterator start, iterator end)
*** const_iterator
    + const_iterator和iterator的主要区别，是const_iterator的operator*返回常量引
      用，这样const_iterator类型的*iter就不能出现在赋值语句的左边
** 向量的实现
** 表的实现
** 栈ADT
*** 栈模型
*** 栈的实现
    + 栈可以很容易的用vector和list来实现
*** 应用
    + 栈在计算机科学中的应用有:
      1) 平衡符号:也就是我们常说的括号匹配
      2) 中缀表达式到后缀表达式的转换
      3) 后缀表达式的计算
      4) 函数的调用
    + 其中，四则表达式的计算就用到了上面提到的(2)和(3): 我们阅读常用的中缀表达式
      作为输入，先利用栈把中缀表达式转化成后缀表达式，然后计算后缀表达式的值，就
      可以得到四则运算的结果。
    + 尾递归:在程序最后一行进行的递归，叫做尾递归，尾递归是非常差劲的使用递归的
      方法，可以通过将代码放到while循环中加以去除，如下
      #+begin_src c
        template <typename Iterator>
        void print(Iterator start, Iterator end, ostream &out = cout)
        {
            if (start == end)
                return;
        
            out << *start++ << endl; // Print and advance start
            print(start, end, out);
        }
        /* previous recursive code can be replaced by following code */
        template <typename Iterator>
        void print(Iterator start, Iterator end, ostream &out = cout)
        {
            while (true)
            {
                if (start == end)
                    return;
                out << *start++ << endl; // Print and advance start
            }
        }
      #+end_src
** 队列ADT
*** 队列模型
    + 如果说栈是后进先出的话，队列就是先进先出
*** 队列的数组实现
    + 队列的数组实现是通过"循环数组"来避免队列在front和back两个图标到达数组尾部
      的情况的。
    + "循环数组"的设计，要求我们要记录数组的长度。因为会出现front在back后面但是
      却合法的情况
*** 队列的应用
    + 看似是常识般的队列，却在算法中有非常重要的应用，比如广度优先算法就是借助于
      队列的帮助
* chapter 4:树
** 预备知识
   +对于大量的输入数据，链表线性访问的时间太长了，不宜使用，所以我们要引入新的数
   据结构:树
*** 树的实现
    + 如果树的子结点数目不限制，那么就是一个传统意义上的树，这种树却由于子结点的
      不固定性，不容易编码实现。
** 二叉树
   + 容易编码实现，且最终应用广泛的，是二叉树
*** 实现
    + 一个二叉树的典型实现如下:
      #+begin_src c
        struct BinaryNode
        {
            Object      element;
            BinaryNode  *left;
            BinaryNode  *right;
        };
      #+end_src
*** 一个例子-表达式树
    + 我们前面说的表达式，如果树叶代表操作数，其他结点代表操作符的话，整个树就可
      以代表一个四则运算。
** 查找树ADT-二叉查找树
   + 对于一个普通的二叉树来说，最代表性的两个操作就是insert和remove
*** insert
    + insert其实就是和contains非常像，对于一个元素如果在指定地方没有找到它，我们
      就该在那个地方插入这个元素
      #+begin_src c++
        /**
         * Internal method to insert into a subtree
         * x is the item to insert
         * t is the node that roots the subtree, t maybe
         * modified, so no const is applied.
         * Set the new root of the subtree.
         */
        void insert(const Comparable &x, BinaryNode* &t)
        {
            /* if the fuction is contains, do nothing here */
            if (t == NULL)
                t = new BinaryNode(x, NULL, NULL);
            else if (x < t->element)
                insert(x, t->left);
            else if (t->element > x)
                insert(x, t->right);
            /* if the fuction is contains, return true here,
               as we find the exact node! */
            else
                ; // Duplicate; do nothing
        }
      #+end_src
*** remove
    + remove的理解难度则要大一点，主要在两点:
      1) 如果要删除的结点有一个(或者零个)子结点的话，那么我们其实是，第一，用中
         间变量保存自己的地址，第二，把自己的地址赋成自己的子结点的内容，第三，
         把中间变量保存的那个地址里面的动态内存删掉。
      2) 理解了第1条，那么第二条比较好理解:如果要删除的结点有两个子结点的话，那
         么，直接删除是非常不明智的，我们采取把这个子节点的"右子树"的"最小结点"
         的值给我们，然后让去删除"右子树"的"最小结点",因为只有这个结点可以放到"
         根"的位置，而且它只会最多有一个子结点
      #+begin_src c++
        void remove(const Comparble &x, BinaryNode* &t)
        {
            if (t == NULL)
                return;    //Item not found, do nothing
            if (x < t->element)
                remove(x, t->left);
            else if(t->element < x)
                remove(x, t->right);
            else if (t->left != NULL && t->right != NULL) // two children
            {
                t->element = findMin(t->right)->element;
                remvoe(t->element, t->right);
            }
            else 
            {
                BinaryNode *oldNode = t; //temp variable
                t = (t->left != NULL) ? t->left : t->right;
                // Do not need let oldNode = NULL, as we stil use it
                delete oldNode; 
            }
        }
      #+end_src
    + 如果把事先排好序的数字输入树，那么一连串的insert操作将会代价非常巨大，因为
      此时的树将只由那些没有左儿子的结点组成，下一节就可以看到对此类情况的一个解
      决办法:平衡二叉树        
** AVL 树
   + AVL树是其每个结点的左子树和右子树的高度最多差1的二叉查找树
   + 为了维持AVL树的这种结构，每次插入的时候，我们都要做很多工作，把要调整的最小
     的子树的根结点叫做a，插入后不平衡的情况有如下四种:
     1) 对a的左儿子的左子树进行一次插入
     2) 对a的左儿子的右子树进行一次插入
     3) 对a的右儿子的左子树进行一次插入
     4) 对a的右儿子的右子树进行一次插入
   + 上面的1和4，以及2和3都是对称的。1和4再经历一次"单旋转"之后就平衡了，2和3再
     经历一次比较麻烦的"双旋转"就平衡了。
** 伸展树
   + 所谓伸展树，它保证从空树开始，任意连续M次对树的操作最多花费O(MlogN)时间，虽
     然并不排除有些操作的时间是O(N)， 而且不存在差的输入序列。
   + 这就比单纯的二分查找树要强了，因为,虽然有些操作是O(N)，但是这个操作调整的过
     程中会把其他结点的高度调整的更浅，访问起来更快。
   + 伸展树的基本想法是,当一个结点被访问后，它就要经过一系列AVL树的旋转被推到根
     上，如果一个结点很深(可能会花费O(N)时间),那么在其路径上就存在许多也相对较深
     的结点，通过重新构造就可以使得对这些结点的进一步访问所花费的时间变少。
   + 比如，对于排序好的序列1-N,从空树构造伸展树的话，开始的时候，伸展树是一个全
     左结点的树，对1的访问要花费N的时间，但是访问完1以后，会对整个树进行伸展操作，
     把树变得更浅，下一次再访问2的时候，时间就不是N-2了，而是N/2,如果树够深的话，
     我们会发现，最好情况下，可以做到logN.
   + 这样看来，伸展树确实是比普通二叉查找树要好，相对于AVL树，伸展树不需要保留平
     衡信息，编码更容易。而且，由于我们把刚访问过的结点移动到了根，下次再访问这
     个结点的时候，时间就会大打加快了。计算机中一个内存被访问，在近期内被再次访
     问的概率很大。
** 树的遍历
   + 树的遍历分四种:
     1) 前序遍历
     2) 中序遍历
     3) 后序遍历
     4) 层次遍历
   + 前三种可以用递归实现，第四种需要用到队列。
** B树
   + 大O模型的前提是，所有的原子操作的时间是相似的，如果问题涉及到数据库，这个假
     设就不成立了，因为数据库是机械特性的，相对于一条机器指令，一条数据库访问的
     代价就太高了，所以，我们在实现数据库的时候，倾向于用比较复杂的数据结构来减
     少IO读取
   + 减少IO读取换句话说，就是降低树的高度，比如31个结点的二叉树高度最小为5，而31
     个结点的的五叉树的最小高度为3。这里就有了M叉查找树的定义。一个完全二叉树的
     高度为log2(N), 而完全M叉树的高度为logM(N)
   + 为了不让M叉查找树退化成二叉树,我们需要某种机制让M叉树保持平衡，其中一种实现
     的方法就是B-树, B+树, B*树(要和B树区分，B树其实就是二叉查找树)
   + 算上二叉树(也就是B树)，我们总结一下四种树:
     - B树: 二叉搜索，每个结点只存储一个关键字，等于则走左结点，大于走右结点
     - B-树:多路搜索，每个结点存储M/2到M个关键字，非叶子结点存储指向关键字范围的
       子结点，所有关键字在整棵树中出现，且只出现一次，非叶子结点可以命中
     - B+树:在B-树基础上，为叶子结点也增加链表指针，所有关键字都在叶子结点中出现，
       非叶子结点作为叶子结点的索引，B+树总是到叶子才接受命中
     - B*树:在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提
       高到2/3
** 标准库中的set和map
   + 前面介绍的vector和list在查找方面的开销都是线性的，STL还提供了两个对数级别时
     间开销(查找，插入，删除)的容器set和map，时间开销上的对数级别，说明了两者都
     是用树作为内部实现的数据结构
*** set
    + set是一个排序后的容器，该容器不容许重复。iterator和const_iterator也嵌套于
      set, 允许遍历.
    + 可以把set理解成是一个内部用树形结构存储的列表，又有顺序的保证，在这个意义
      上来看set和vector以及list都是非常相似的，所以vector和list的方法,比如begin,
      end, size, empty都可以利用在set上
    + 因为set不允许重复，所以插入必然是特别一点的:
      #+begin_src c++
        /* 除了返回是否插入成功的bool值以外，还返回一个iterator
         *  这个iterator是新插入项的地址，或者是在插入失败的情况下
         * 指示导致插入失败的项的地址，从而进行删除，而不需要再次进
         * 行查询操作
         */
        pair<iterator, bool> insert(const Object &x);
        pair<iterator, bool> insert(iterator hint, const Object &x);
      #+end_src
    + 查找函数返回的是具体的iterator地址
      #+begin_src c++
        iterator find(const Object &x) const;
      #+end_src
    + 排序的话，是使用less<Object>调用operator<来进行的
*** map
    + 针对set不能重复的缺点，又发明了map这种数据结构，它的特点是key不可以重复，
      但是value可以重复。其实就是key值用来构建树形结构，多加了个域来存储数据
    + map有一个特别的获取键值的操作，可惜由于返回值是引用，所以这个操作无法应用
      到常量的map
      #+begin_src c++
        ValueType & operator[] (const KeyType & key);
      #+end_src
    + 下面的例子来演示map的重要函数应用
      #+begin_src c++
        map<string, double> salaries;
        
        salaries["Pat"] = 75000.00;
        cout << salaries["Pat"] << endl;
        cout << salaries["Jan"] << endl;
        
        map<string, double>::const_iterator itr;
        itr = salaries.find("Chris");
        if (itr == salaries.end())
            cout << "Not an employee of this company" << endl;
        else
            cout << itr->second << endl;
      #+end_src
*** set 和 map的实现
    + set 和 map的基本操作是对数级别的，显然是使用了树的数据结构，具体点说，是红
      黑树
* chapter 5: 散列
** 基本思想
   + 前面讲过的各种树，其实是为了便于排列，数据结构中都包含了顺序的信息，而散列
     只是能已常数时间插入，删除和查找的技术，为了达到常数级别，它用了散列函数和
     处理冲突的方法，所以没有保留顺序信息。findMin, findMax等肯定是没有
** 散列函数
   + 将每个键映射到0到TableSize-1这个范围的某个数的映射方法，就叫散列函数
** 分离链接法
   + 如果散列函数把两个元素映射到相同的位置，那么就会产生一个冲突，最常见的解决
     冲突的方法就是分离链接法(separate chaining)
   + 插入的时候，我们常用前插法，因为最后插入的元素最有可能不久再被使用
** 不使用链表的散列表
   + 分离链接散列算法的缺点是使用的链表要重新分配空间，因此会导致算法有些慢。另
     外一种解决冲突的办法是，当冲突发生的时候，就尝试选择另外的单元
   + 更正式地，单元h0(x), h1(x), h2(x)...依次进行选择，其中
     #+begin_example
     hi(x) = (hash(x) + f(i)) mod TableSize
     #+end_example
   + 因为所有数据都是放到表中的，所以要求这个方案中所需要的表要比分离链接散列需
     要的表要大，一般要达至少有一半以上的空余的单元(也就是λ>0.5)，我们称这样的
     表为探测散列表，下面有三种常见的利用探测散列表的方法
*** 线性探测
    + 一般情况下是f(i) = i,就是如果发现冲突，那就把数据放到下一个空闲的地址
    + 算法的效果和λ的值关系较大，在λ比较大的情况下可以考虑使用 
    + 线性探测的缺点是容易形成"一次聚集"，就是数据集中在某一块，使得下次插入变得
      更加的没效率
*** 平方探测
    + 一般情况下是f(i) = i^2
    + 解决了线性探测的"一次聚集",但是又引入了"二次聚集",就是散列到同一位置上的那
      些元素将探测相同的备选单元
*** 双散列
    + 也就是f(i) = i*hash2(x)
    + 解决了"二次聚集"问题，但是对hash2函数的选择很难
** 再散列
   + 再散列是指当表填的比较满的时候，要重新做一个容量是当前表两倍的表，这是个非
     常昂贵的操作，不要和"双散列"混淆
** 可扩展散列
   + 我们在讲B树的时候说过，如果涉及到磁盘操作，那么大O定理不再适用，因为一次IO
     操作的代价远远大于一次机器指令.也就是说，如果数据不能一次放到内存，那么减少
     IO操作的次数就是算法的重点
   + 在散列领域和B树有异曲同工之妙的就是可扩展散列(extendible hashing)
* chapter 6:优先队列(堆)
** 模型
   + 我们知道队列(queue)，是先进先出的数据结构，而优先队列呢，就是队列总体上遵循
     先入先出的选择，但是个别元素个别对待
   + 优先队列有很多应用场景，比如操作系统中的调度策略，总体上是谁先来，谁先运行，
     但是有些进程需要运行很少的时间就结束了，那么我们就要把他们的优先级提高一些。
   + 再优先队列中，主要的两个操作，一个是insert,一个是deleteMin,分别对应于普通队
     列的enqueue和dequeue
** 一些简单的实现
   + 优先队列是始终保持一个最小值，每次删除后又能马上找到最小值，我们最直观的两
     个实现的数据结构是:
     1) 链表 : 缺点非常明显，每次都要遍历才能找到合适的删除候选，时间复杂度为
        O(N)
     2) 二叉查找树: 虽然是以O(logN)的复杂度来完成insert和deleteMin这两个操作，
        但是由于我们在数据结构中维护了大量的无用信息(比如整个序列的顺序),说明我们
        数据结构还有改进的空间
** 二叉堆
*** 结构性质
    + 所谓堆就是一颗完全二叉树(除了最底层以外，都是满的), 既然我们用二叉查找树都
      是浪费，那用完全二叉树岂不是更浪费? 其实不然，因为完全二叉树特殊的性质，我
      们可以不用链表，而只用数组来表示他们。
    + 所谓数组表示法，就是把一颗满二叉树按层次遍历以后放到数组
      #+begin_example
                                +---+
                                |A  |
                                +---+
                                |   |
                       +--+<--+-+   +-+->+--+
                       |B |              |C |
                       +--+              +--+
                       |  |              |  |
                +--+<--+  +->+--+  +--+<-+  +->+--+
                |D |         |E |  |F |        |G |
                +--+         +--+  +--+        +--+
                |  |         
         +--+ <-+  +->+--+  
         |H |         |I |
         +--+         +--+
        
        |---+---+---+---+---+---+---+---+---+---+----+----|
        |   | A | B | C | D | E | F | G | H | I |    |    |
        |---+---+---+---+---+---+---+---+---+---+----+----|
        | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |
        |---+---+---+---+---+---+---+---+---+---+----+----|
      #+end_example
    + 二叉堆呢，就是对于堆中每个结点，X的父亲结点，小于他的两个儿子结点,根除外，
      因为根没有父亲结点(可以看到，不像二叉查找树，我们没有一定要求左节点小于右
      结点，也就没有维护顺序信息)
*** 基本操作
    + insert:插入的过程其实就是在树的最后加入一个新的结点，然后加入新的值。之后
      和父辈进行比较比父辈小就和父辈替换，然后依次进行下去，直到新插入的数值找到
      合适的位置。
    + 从上图看，就是在10处插入J,然后J和自己的父亲E比较大小哦，如果替
      换了E，再和B比较，如果替换了B再和A比较
    + deleteMin:另外一个主要的操作是删除最小元素，我们知道二叉堆的根节点就是最小
      的，去掉根结点后，我们就可以重新的组织堆的结构，从根开始，把两个子结点和最
      后一个结点比较，三者最小的做根，然后一直下去，直到平衡
    + 从上图看，就是把A删掉，然后B,C,I比较，小的放到A的位置上，如果I成功的放置的
      话，删除结束，如果没有的话，比如是B到了A,那么B的位置又空下来了，接下来，
      D,E，I再比较，依次继续，知道I找到位置。I原来的位置就被删除了。从总体看，就
      是数组少了一个成员，然后其余成员还是维护了二叉堆的性质
** 优先队列的应用
   + 选择问题:找一个含有N个元素序列的第K大的值，利用二叉堆这种数据结构，我们可以
     有两者办法解决，复杂度都小于简单排序的O(N^2):
     1) 先将这N个元素读入到一个数组，然后对该数组做buildHeap操作，这个过程是
        O(N), 然后执行K次deleteMin操作，复杂度是O(K*logN)，剩下的就是第K大，整个
        过程的复杂度是O(N + K*logN):
        - 如果 K = O(N/logN)，那么运行时间主要是决定于buildHeap
        - 如果 K = N/2, 那么运行时间就是O(NlogN)
        - 如果 K = N，那么其实就是对整个数组进行了排序
     2) 第二种方法，把K个数读入数组，然后buildHeap,这次是build一个最大堆，复杂度
        为O(K), 之后把剩下的N-K个一次和最大堆的最大值比较，如果小于那个最大值，
        就用新值替换那个最大值，最后剩下的那个最大堆的最大值就是第K大的值。这个
        过程的复杂度为O((N-K)logK), 整个过程的时间复杂度为O(K + (N-K)logK) =
        O(NlogK), 该算法也指出，找出中位数的复杂度为O(NlogN)
** d堆
   + d堆就是对二叉堆的一个升华,所有节点都有d个儿子的堆,就叫做d堆
   + d堆的insert操作复杂度降低到了O((logd)N),但是在deleteMin和Merge操作的时候,速
     度就慢多了
** 左堆式
   + 左堆式是为了更快的进行合并操作而设计的堆结构
** 斜堆
   + 斜堆是左式堆的自调节形式,斜堆和左式堆的关系,就好像伸展树和AVL树的关系一样,
     斜对的操作最坏的情形运行时间为O(N),然而,正如伸展树一样,对任意M次操作,总的最
     坏情况运行时间是O(MlogN)
** 二项队列
     + 二项式堆当然还是保留堆最主要的特性,那就是logN时间能够取到极值
     + 二项式堆是d堆,但是是能够支持平均最坏logN,平均常数时间插入操作的d堆
     + 左堆式和斜堆都是d堆,但是他们的插入操作要话费logN时间
** 标准库中的优先队列
   + 在STL中,二叉堆是通过<queue>中的priority_queue的类模板实现的,它是实现的一个
     最大堆,而不是最小堆,最小堆的实现,可以通过添加一个比较函数来实现,如下
     #+begin_src c++
       #include <iostream>
       #include <vector>
       #include <queue>
       #include <functional>
       #include <string>
       using namespace std;
       
       // Empty the priority queue and print its contents.
       template <typename PriorityQueue>
       void dumpContents(const string& msg, PriorityQueue& pq)
       {
           cout << msg << ":" << endl;
           while (!pq.empty()) {
               cout << pq.top() << endl;
               pq.pop();
           }
       }
       
       //Do some inserts and removes (done in dumpContents)
       int main()
       {
           priority_queue<int>      maxPQ;
           priority_queue<int, vector<int>, greater<int>> minPQ;
       
           minPQ.push(4); minPQ.push(3); minPQ.push(5);
           maxPQ.push(4); maxPQ.push(3); maxPQ.push(5);
       
           dumpContents("minPQ", minPQ);
           dumpContents("maxPQ", maxPQ);
       
           return 0;
       }
     #+end_src




